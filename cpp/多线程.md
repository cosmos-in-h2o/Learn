# 多线程
> 为了避免示例代码冗杂，去掉了头文件引入代码（相关头文件会在示例前说明）以及`using namespace std;`，有的时候还会使用省略号代替main函数的声明和花括号等。
## 1-概念
### 1.1-并发
多个任务一起执行叫做并发，但大多数时候cpu的核心数比执行的任务数要少，因此大多数时候的并发是**虚假的**，只是在不同任务间来回切换（上下文切换，并且这个切换是随机的）。
### 1.2-并行
cpu同时执行多个任务时（**真正同时执行**而不是切换任务），叫做并行。
### 1.3-进程
一个执行的程序叫做一个进程。
### 1.4-线程
执行任务的通道，每一个进程都有一个主线程，**二者有一出现另一也出现，有一消失另一也消失**,主线程在c/c++中就是main函数。通常情况下，创建的子线程会随主线程消失而消失。线程不宜过多，一是造成资源浪费，每一个线程都有其对应的栈，需要消耗一定的资源;二是会拖慢程序速度，过多的线程会造成程序运行时进行频繁的上下文切换，拖慢程序速度。
## 2-thread
### 2.1-线程创建与运行
首先需要包含头文件`#include<thread>`，然后可以通过以下方式创建一个线程并开启线程：
```cpp
void myThread(){
    std::cout<<"thread start\n";
    std::cout<<"thread end\n"
}
int main(){
    std::thread t(myThread);
    t.join();
}
```
main函数中第一行是创建并启动线程，第二行的join函数代表主线程与子线程**汇合（不要理解为加入）**，也就是当主线程**干完其他事后**来到这行主线程会等待子线程执行完后再执行。如果不汇合则需要调用**detach函数**，此时主线程结束子线程随之结束。\
还有几个创建方法：

```cpp
struct thread_obj{
    void operator()(){
        cout<<"子线程\n";
    }
};
int main(){
    thread t(thread_obj());//使用对象创建
    thread t2([]{cout<<"子线程\n";});//使用lambda表达式创建
    t.join();
    t2.join();
}
```
如果函数带参可以在thread的构造函数里将参数传入，比如：
```cpp
thread t(func,arg,arg2...);
```
另外，一个线程只能执行一次detach函数或join函数,可以使用joinable函数来判断线程能否被join，如下
```cpp
void func();
......
thread t(func);
t.detach();
//t.join();//error
if(t.joinable())
    t.join();
......
```
### 2.2-参数传递
像是上面的例子，可以直接在thread的构造方法里添加要传递的参数，但要注意的是这些参数会**拷贝**至新线程的内存空间中(同临时变量一样)。即使函数中的参数是引用，原因是thread的构造函数不知道参数应该是引用还是值，如果需要传递引用则需使用`std::ref()`强转一下。

### 2.3-this_thread
|函数|用途|
|----|----|
|std::this_thread::get_id()|获取线程id|
|std::this_thread::yield()|放弃线程执行，回到就绪状态|
|std::this_thread::sleep_for(std::chrono::seconds(x))|暂停x秒|
|std::this_thread::sleep_until()|暂停直到某个时刻|
## 3-互斥量
### 3.1-竞争关系
当两个及以上线程**修改**同一个数据时他们便有了竞争关系，后果可能会使结果与预期不一致，例如以下代码：
```cpp
int G_V=0;

void taskFunc(){
    for(int i=0;i<10000000;++i){
        G_V++;
        G_V--;
    }
}
int main()
{
    thread task1(taskFunc);
    thread task2(taskFunc);
    task1.join();
    task2.join();
    cout<<G_V<<"\n";
    return 0;
}
```
预期的结果是0,但实际运行中每次结果都不一致（如果都是0可能是编译器优化了，需要降低优化等级）原因是自增与自减操作实际就是一个变量赋值的操作，cpu会先从内存中取出变量放进寄存器，然后进行计算，最后将计算的结果储存到原来的内存中，而当两个或多个线程同时读取了同一片内存，执行了他们各自的运算后会对那片内存进行覆写，这一过程存在许多不确定性。
### 3.2-std::mutex
#### 3.2.1-mutex::lock与mutex::unlock
为了防止以上情况的出现，我们需要对数据上锁，也就是使用std::mutex，它在头文件`<mutex>`中：
```cpp
mutex mtx;
int G_V=0;

void taskFunc(){
    for(int i=0;i<10000000;++i){
        mtx.lock();
        G_V++;
        G_V--;
        mtx.unlock();
    }
}
......
```
我在循环的开始与结束分别写了`mtx.lock();`与`mtx.unlock();`，这两句代码的意思就是上锁与解锁。假如两个线程叫T1与T2,他们同时被开启，T1先走到了循环中，执行了上锁语句，当T2想往下执行的时候看到了上锁的语句就会等待解锁后再与T1抢着执行。
#### 3.2.2-mutex::try_lock
```cpp
mutex mtx;
int G_V=0;

void taskFunc(){
    for(int i=0;i<10000000;++i){
        if(mtx.try_lock()){
            G_V++;
            mtx.unlock();
        }
    }
}
int main()
{
    thread task1(taskFunc);
    thread task2(taskFunc);
    task1.join();
    task2.join();
    cout<<G_V<<"\n";
    return 0;
}
```
`mtx.try_lock()`的意思是尝试上锁，如果已经被上锁就返回false,如果未被上锁就返回true并上锁。它不像`lock`一样，它是**非阻塞**的，如代码中所写，若task1先尝试去上锁并且成功了，在task1做一些事情的同时task2尝试上锁，未成功，**立刻返回false**，所以task2会跳过这次循环，本次操作与`continue;`等价，因此最后运行的结果也会随机而不是每次都是20000000。
### 3.3-死锁
死锁是指不正确的上锁或解锁操作导致线程进入一直阻塞的状态，以下是一些死锁的例子：
```cpp
mutex mtx;
void taskFunc(){
    mtx.lock();
    //do something
}
```
上面的代码指执行了上锁而为解锁，下一次执行便会一直阻塞不能往下执行。
```cpp
mutex mtx;
void taskFunc(){
    mtx.lock();
    //do something
    return;
    mtx.unlock();
}
```
上面的代码执行了上锁也执行了解锁，但在中途退出了函数，实际上也并没有解锁。
>如果函数中途抛出异常也会进入死锁状态，可以通过try catch来捕获异常对它正常解锁。
```cpp
mutex mtx1;
mutex mtx2;
void taskFunc1(){
    mtx1.lock();
    mtx2.lock();
    //do something
    mtx1.unlock();
    mtx2.unlock();
}
void taskFunc2(){
    mtx2.lock();
    mtx1.lock();
    //do something
    mtx2.unlock();
    mtx1.unlock();
}
```
上面的两个函数都对两个mutex执行了上锁以及解锁操作，但顺序不同，这就导致若两个函数同时执行，会分别对mtx1和mtx2执行上锁操作，当他们接着往下运行时就会发现自己需要的另一个锁已经锁上了，两者都会进入阻塞。
### 3.4-lock_guard
为了防止在线程执行过程中出现异常或退出时未解锁，可以使用lock_guard来解决：
```cpp
mutex mtx;
void taskFunc(){
    lock_guard<std::mutex> lock(mtx);
    //do something
    return;
}
```
它的本质就是在构造函数执行上锁操作，在析构时执行解锁操作。
>这种做法也被称作RAII
### 3.5-unique_lock
类似于lock_guard，都是利用RAII来实现上锁与解锁，不同的是unique_lock可以自由控制解锁的时刻，并且unique_lock会接管对象，拥有对象的所有权，lock_guard则没有。
```cpp
std::mutex mtx;
void taskFunc(){
    unique_lock<std::mutex> lock(mtx);
    //do something
    return;
}
```
可以这么写，这与上面lock_guard的示例代码效果是一致的，你也可以控制它在任意时刻解锁：
```cpp
std::mutex mtx;
void taskFunc(){
    unique_lock<std::mutex> lock(mtx);
    //do something
    lock.unlock();
    return;
}
```
### 3.6-recursive_mutex
以下代码会报错：
```cpp
...
mutex mtx;
void taskFunc(int i){
    mtx.lock();
    cout<<i;
    taskFunc(--i);
    mtx.unlock();
}
```
原因是mtx多次上锁，也就是说我们无法在使用mutex时实现递归操作。但可以使用recursive_mutex做到这一点，只需要把上面代码中的`mutex mtx;`改成`recursive_mutex mtx;`
### 3.7-scoped_lock
可以接受多个mutex的lock_guard。
### 3.8-call_once
保证函数在多个线程中只被调用一次，需要配合`std::once_flag`来使用
```cpp
void initialize() {
    std::cout << __FUNCTION__ << std::endl;
}

std::once_flag of;
void my_thread() {
    std::call_once(of, initialize);
}

int main() {
    std::thread threads[10];
    for (std::thread &thr: threads) {
        thr = std::thread(my_thread);
    }
    for (std::thread &thr: threads) {
        thr.join();
    }
    return 0;
}
```
以上代码中程序只会输出一次"initialize"。
### 3.x-其他
`template <class L1, class L2, class... L3> int try_lock(L1&, L2&, L3&...);`尝试为所有传进来的互斥量上锁，返回值比较复杂，可以自行了解。\
`template <class L1, class L2, class... L3>void lock(L1&, L2&, L3&...);`对所有传进的mutex上锁，但上锁顺序是不确定的。该函数保证: 如果成功，则所有mutex全部上锁，如果失败，则全部解锁。\
互斥量时间类的上锁，例如`std::mutex::try_lock_for()`，不做介绍，自行了解。\
## 4-条件变量
首先需要引入相关头文件`#include <condition_variable>`。
先来看以下代码，猜测意思：
```cpp
mutex mtx;
condition_variable cv;
queue<int> q;

void producer(){
    int i=0;
    while(true){
        unique_lock<mutex> lock(mtx);
        q.push(i);
        cv.notify_one();
        i++;
    }
}
void customer(){
    while(true){
        unique_lock<mutex> lock(mtx);
        if(q.empty()){
            cv.wait(lock);
        }
        cout<<q.front()<<'\n';
        q.pop();
    }
}
int main(){
    thread t1(producer);
    thread t2(customer);
    t1.join();
    t2.join();
    return 0;
}
```
这段代码开启了两个线程，分别是producer和customer,他们分别做生产数据和消费数据的工作。执行结果是从零开始，递增地打印数字。接下来请暂时忽略有关条件变量的语句（指与`condition_variable cv;`相关的语句），先从生产者来看，它在循环中向一个队列添加数据然后对下一次添加的数据执行自增操作；再来看消费者，它先打印队列第一个元素然后删除队列第一个元素（队列是一种先进先出的数据结构）；这两个线程是同时执行的，所以在消费者线程里执行`cout<<q.front()<<'\n';`与`q.pop();`有可能报错，因此我们可以添加一个if语句来判断：
```cpp
if(!q.empty()){
    cout<<q.front()<<'\n';
    q.pop();
}
```
但这样执行太过低效，我们完全可以将其阻塞，等达到条件时恢复，而不是不停判断是否达到条件，可以通过使用条件变量（condition_variable）来实现这个目的。先来看消费者的这三行使用条件变量的代码：
```cpp
if(q.empty()){
    cv.wait(lock);
}
```
首先判断队列是否为空，空的话就调用了一个`std::condition_variable::wait(std::unique_lock)`函数，这行代码意思为使该线程进入阻塞，而要传入一个锁是因为此线程进入阻后不应该拥有锁，所以需要对其执行`unlock()`操作，在wait内部会对传入参数执行此操作；再来看生产者，当添加数据之后就执行`condition_variable::notify_one()`函数，意思为通知某个正在阻塞的线程恢复正常（也可以使用`condition_variable::notify_all()`通知所有正在阻塞线程恢复正常）；再回到消费者，当他收到通知后就会执行`lock()`操作，成功获取锁后就会接着往下执行。
## 5-异步执行
需要引入头文件`#include<futrue>`
### 5.1-promise与future
#### 5.1.1-设置promise的值
promise是一个模板类，其声明为`template<typename R> class promise;`，可以将它理解为上文条件变量中的生产者。\
future也是一个模板类，声明类似于promise，可以理解为上文中的消费者。\
结合上面两句介绍来猜测下面代码的意思：
```cpp
int main(){
    promise<string> pro;
    future fut=pro.get_future();
    thread t([](future<string>* fut_ptr){
        cout<<fut_ptr->get()<<endl;
    }
    ,&fut);
    cout<<"begin..."<<endl;
    this_thread::sleep_for(chrono::seconds(3));
    pro.set_value("end...");
    t.join();
}
```
进入main函数后，创建了一个promise对象，接着又创建了一个future对象，使用了赋值运算符将上文创建的promise对象与future对象**绑定**；随后开启了一个线程，线程将future绑定的promise的值输出，但如果promise没有值则会进入阻塞等待值；下面就是一个等待语句，等待3秒后promise设置了值，此时线程不再阻塞，打印了promise的值。\
> 注意：promise和future都不支持拷贝构造，仅支持移动构造，上面代码中的赋值接收的也是一个右值；一个promise只能与一个future绑定，也就是说`promise::get_future()`只能被调用一次，多次调用会报异常；若promise在销毁时仍未设置值，在调用`future::get()`时会报异常；`promise::set_value()`与下文要讲的`promise::set_exception()`都只能调用一次。
#### 5.1.2-promise设置异常
promise也可以设置异常让future捕获，如：
```cpp
int main(){
    promise<string> pro;
    future fut=pro.get_future();
    thread t([](future<string>* fut_ptr){
                 try {
                     fut_ptr->get();
                 } catch (std::logic_error &e) {
                     std::cerr << "error: " << e.what() << std::endl;
                 }
             }
            ,&fut);
    cout<<"begin..."<<endl;
    this_thread::sleep_for(chrono::seconds(3));
    pro.set_exception(std::make_exception_ptr(std::logic_error("caught")));
    t.join();
}
```
#### 5.1.3-promise类型参数为void
promise的模板类型参数可以为void，仅仅用来实现取消阻塞，和条件变量类似。
#### 5.1.4-std::promise所在线程退出时
`std::promise::set_value_at_thread_exit`:线程退出时，std::future收到通过该函数设置的值。
`std::promise::set_exception_at_thread_exit`:线程退出时，std::future则抛出该函数指定的异常。
### 5.2-package_task
与promise相似，可以与一个future绑定，但它的构造函数可以接受一个函数对象：
```cpp
int main(){
    packaged_task<int(int,int)>pt(add);
    future fut=pt.get_future();
    std::thread t(std::move(pt), 1, 2);
    cout<<fut.get();
    t.join();
}
```
上面的代码与promise的类似，在构造thread时传入了pt的右值引用，因为packaged_task与promise一样只有移动构造函数没有拷贝构造；随后等待计算结果出来后打印。\
packaged_task支持无参构造，但构造后无法立即使用，必须赋值后才可使用，是否可以使用可以通过调用`packaged_task::valid()`来判断。\
一些成员函数：
- `bool packaged_task::valid()`：判断是否可以使用。
- `void std::packaged_task::operator()(ArgTypes...)`：调用一次函数对象，并将结果反馈给与其对应的future，而不会立刻返回结果。
- `void std::packaged_task::reset()`：解除绑定。
### 5.3-future与async
#### 5.3.1-future
上面已经对future做了部分讲解，接下来会讲解future中其他的成员函数
- `future::share()`
是为了方便多个线程中数据共享，返回一个`shared_future`类型，这个类型可以拷贝可以移动，可以多次调用get函数来实现多个线程的数据共享
```cpp
int main() {
    std::promise<std::string> promise;
    std::future future=promise.get_future();
    std::shared_future shared_future1=future.share();
    promise.set_value("promise");
    std::cout<<shared_future1.get()<<std::endl;
    std::cout<<shared_future1.get()<<std::endl;
    return 0;
}
```
- `future::wait()`
等待结果出来。
- `future::wait_for()与future::wait_until()`
wait_for等待指定时长，wait_until则等待到指定的时间点。返回值是一种枚举类型：
  - std::future_status::ready 数据已就绪，可以通过get获取了。 
  - std::future_status::ready 超时，数据还未准备好。
  - std::future_status::ready 这个和std::async相关，表明无需wait，异步函数将在get时执行。
- `future::valid()`
当与生产者绑定后此函数返回true，否则返回false；生产者包括`std::promise::get_future()`，`std::packaged_task::get_future()`和下文要讲的`std::async`。
#### 5.3.2-共享状态
在C++中，共享状态是指多个线程或进程之间共享的数据或资源。共享状态可能是一个简单的变量，也可以是一个复杂的数据结构，例如数组、列表或对象。\
在多线程编程中，共享状态可能会引发并发访问的问题，例如竞态条件（race condition）和数据竞争（data race）。
#### 5.3.3-async
它是一个函数模板，声明为
```cpp
template <class Function, class... Args>
std::future<typename std::result_of<Function(Args...)>::type>
        async(Function&& f, Args&&... args);
```
可以看到，它返回传入函数的返回值类型的一个future，也就是说它能够直接与future绑定，实现与packaged_task类似的效果：
```cpp
int main() {

    std::future future=std::async([]{return 0;});
    std::cout<<future.get();
    return 0;
}
```
而async内部具体是如何运行的是不确定的（可能创建了一个线程，也可以使用了线程池）\
async还有一个重载，声明为：
```cpp
template <class Function, class... Args>
std::future<typename std::result_of<Function(Args...)>::type>
        async(launch policy,Function&& f, Args&&... args);
```
可以看到，第一个参数需要传入一个launch类型的对象，这是一个枚举类，声明为：
```cpp
enum class launch {
    async = 1,
    deferred = 2,
    any = async | deferred
};
```
launch::async表示异步执行;launch::deferred表示任务将在调用`std::future::get()`或`std::future::wait()`成员函数被调用时延迟执行，任务将在调用这些函数时在当前线程中同步执行;launch::any表示任意都可以，由编译器决定，clang会优先使用async策略，如果创建线程失败，则使用deferred策略。
## 6-thread_local
它用于指定变量在每个线程中具有独立的副本，每个线程都可以独立访问和修改该变量的副本，而不会互相干扰，如：
```cpp
thread_local int counter = 0;
void increment() {
    counter++;
}
void printCounter() {
    std::cout << "Counter value in thread " << std::this_thread::get_id() << ": " << counter << std::endl;
}
int main() {
    std::thread t1(increment);
    std::thread t2(increment);
    t1.join();
    t2.join();
    printCounter();
    return 0;
}
```
输出结果为0。\
注意：
- thread_local 变量在每个线程中都会进行初始化，即使没有显式初始化也会有默认值。
- thread_local 变量的生命周期与所属线程一致。当线程创建时，变量会被创建并初始化；当线程终止时，变量会被销毁。
## 7-原子类型
需要引入头文件`#include<atomic>`，此头文件所包含的所有类均不可被拷贝与移动。\
原子在化学变化中不可被分割，而原子操作在程序执行中也无法被分割或中断，使用原子操作可以有效地避免数据竞争的问题，并且性能高于mutex。 
### 7.1-atomic_flag
atomic_flag是一种最简单的原子操作，自身只有两种操作：`atomic_flag::test_and_set()`和`atomic_flag::clear()`本质就是把某个成员变量设置为true与false;\
atomic_flag有三种状态，分别是set，clear与未设置；当使用无参构造时是未设置的状态，可以在构造时使用`ATOMIC_FLAG_INIT`的宏使其为clear状态。\
`atomic_flag::test_and_set()`被调用时，当自身状态为clear时会返回false并设置为set状态，否则返回true；`atomic_flag::clear()`被调用时只会将状态设置为clear。\
以下代码使用atomic_flag实现了简单的互斥锁：
```cpp
std::atomic_flag lock = ATOMIC_FLAG_INIT;

void criticalSection(int threadId) {
    while (lock.test_and_set(std::memory_order_acquire)) {
        // 等待锁可用
    }
    std::cout << "Thread " << threadId << " entered critical section." << std::endl;
    std::this_thread::sleep_for(std::chrono::seconds(1));
    std::cout << "Thread " << threadId << " exiting critical section." << std::endl;
    //释放锁
    lock.clear(std::memory_order_release);
}

int main() {
    std::thread t1(criticalSection, 1);
    std::thread t2(criticalSection, 2);
    t1.join();
    t2.join();
    return 0;
}
```
> atomic_flag是是一种自旋锁的基本构建块；自旋锁是指循环检测锁是否可用。

在程序中，`test_and_set()`与`clear()`都带有一个参数，这个参数是顺序，这里简单描述一下：

| 序号 | 值                                 |意义|
|----|-----------------------------------|----|
| 1  | memory_order_relaxed              |宽松模型，不对执行顺序做保证|
| 2  | memory_order_consume（c++20后面不讲）   |当前线程中,满足happens-before原则。当前线程中该原子的所有后续操作,必须在本条操作完成之后执行|
| 3  | memory_order_acquire              |当前线程中,读操作满足happens-before原则。所有后续的读操作必须在本操作完成后执行|
| 4  | memory_order_release              |当前线程中,写操作满足happens-before原则。所有后续的写操作必须在本操作完成后执行|
| 5  | memory_order_acq_rel              |当前线程中，同时满足memory_order_acquire和memory_order_release|
| 6  | memory_order_seq_cst              |最强约束。全部读写都按顺序执行|
### 7.2-atomic
是一个模板类，对指针以及数值类型做了特化，`atomic<数值类型>`拥有更多的更多的成员函数。\
#### 7.2.1-atomic::operator=()
声明：
```cpp
T operator=( T desired ) noexcept;
T operator=( T desired ) volatile noexcept;
atomic& operator=( const atomic& ) = delete;
atomic& operator=( const atomic& ) volatile = delete;
```
原子地赋 desired 给值原子变量。等价于 store(desired)。
#### 7.2.2-atomic::is_lock_free()
检查此类型所有对象上的原子操作是否免锁，无锁则返回true，否则为false
#### 7.2.3-atomic::store()
声明：
```cpp
void store( T desired, std::memory_order order = std::memory_order_seq_cst ) noexcept;	
void store( T desired, std::memory_order order = std::memory_order_seq_cst ) volatile noexcept;
```
原子地以 desired 替换当前值。按照 order 的值影响内存。\
order 必须是 std::memory_order_relaxed 、 std::memory_order_release 或 std::memory_order_seq_cst 之一。否则行为未定义。
#### 7.2.4-atomic::load()
```cpp
T load( std::memory_order order = std::memory_order_seq_cst ) const noexcept;
T load( std::memory_order order = std::memory_order_seq_cst ) const volatile noexcept;
```
原子地加载并返回原子变量的当前值。按照 order 的值影响内存。\
order 必须是 std::memory_order_relaxed 、 std::memory_order_consume 、 std::memory_order_acquire 或 std::memory_order_seq_cst 之一。否则行为未定义。
#### 7.2.5-atomic::operator T()
相当于load()
#### 7.2.6-atomic::exchange()
原子地替换原子对象的值并获得它先前持有的值（operator=()是获取传入的值）。
#### 7.2.7-atomic::compare_exchange_weak()
顾名思义，就是先比较原子对象所封装的值，再进行交换操作，它的声明如下：
```cpp
bool compare_exchange_weak( T& expected, T desired, std::memory_order success, std::memory_order failure) volatile noexcept;
bool compare_exchange_weak( T& expected, T desired, std::memory_order success, std::memory_order failure) noexcept;
bool compare_exchange_weak( T& expected, T desired, std::memory_order order = std::memory_order_seq_cst) volatile noexcept;
bool compare_exchange_weak( T& expected, T desired, std::memory_order order = std::memory_order_seq_cst) noexcept;
```
如果原子对象所封装的值与期待值不同，则修改期待值为封装的值并有可能返回false；若相同，则修改封装值为desired并返回true。要注意的是weak版本有时会返回伪false。但它在某些平台下有更好的性能，通常用在循环算法中，即使返回伪false也可以通过简单的重试来尝试再次操作。
#### 7.2.8-atomic::compare_exchange_strong()
其声明为：
```cpp
bool compare_exchange_strong( T& expected, T desired,std::memory_order success,std::memory_order failure ) noexcept;
bool compare_exchange_strong( T& expected, T desired,std::memory_order success,std::memory_order failure ) volatile noexcept;
bool compare_exchange_strong( T& expected, T desired,std::memory_order order =std::memory_order_seq_cst ) noexcept;
bool compare_exchange_strong( T& expected, T desired,std::memory_order order = std::memory_order_seq_cst ) volatile noexcept;
```
与weak一致，都是先比较再交换，但strong是强保证的，即相同就返回true，不同就返回false，不会出现伪false。
### 7.3-memory_order
#### 7.3.1-引入
假如我们现在有两个线程分别叫T1和T2，T1执行任务A与任务B，T2执行任务C和任务D，假如ABCD四个任务都是原子操作，在CPU不对指令进行重排时会有六种情况：ABCD、ACBD、ACDB、CABD、CADB、CDAB。而如果A与B没有关联，CPU为了提高代码执行速度在不影响程序执行结果的情况下是有可能乱序执行，也就是有可能先执行B再执行A或者限制性D再执行C，而这些优化在多线程中有可能引发一些错误；\
为了解决这些问题需要引入memory_order。
#### 7.3.2-宽松次序
memory_order_relaxed只保证原子操作，不对其他任何顺序进行保证，通常用于计数器,例如：
```cpp
std::atomic<int> count{0};
void f()
{
    for (int n = 0; n < 1000; ++n) {
        count.fetch_add(1, std::memory_order_relaxed);
    }
}
int main()
{
    std::thread threads[10];
    for (std::thread &thr: threads) {
        thr = std::thread(f);
    }
    for (auto &thr : threads) {
        thr.join();
    }
    assert(count == 10000); // 永远不会失败
    return 0;
}
```
#### 7.3.3-释放-获取次序
包括memory_order_acquire、memory_order_release以及memory_order_acq_rel；\
acquire表示该操作之前的所有读写操作都无法被重排到该操作之后；\
release表示该操作之后的所有读写操作都无法被重排到该操作之前；\
这两个可以理解为需要先发布再执行其他操作，需要先执行完其他操作才能获取。
memory_order_acq_rel带此内存顺序的读修改写操作既是获得操作又是释放操作。当前线程的读或写内存不能被重排到此存储前或后。所有释放同一原子变量的线程的写入可见于修改之前，而且修改可见于其他获得同一原子变量的线程。
#### 7.3.4-顺序一致性
指的就是memory_order_seq_cst，如果是读就是acquire，写就是release。
